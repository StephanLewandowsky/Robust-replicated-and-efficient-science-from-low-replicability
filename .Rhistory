nMI <- c(1) #number of misinfo tokens at input
nR <- c(0,1,3) #number of retractions
nSamples <- 4
nTokens <- 12
nRep <- 1000
ulli <- 0 #ulli's model = 1, SL model = 0
pSampleNegTag <- .65 #no longer a probability but a proportion
magnitudeMI <- c(11,.9) #starting "strength" and slope of MIs across repetitions
#misinfo scores in E1
scores <- c(.39,4.48,1.83,1.87,5.67,3.22,1.7)
scores <- scores-scores[1] #form zero baseline
#get all conditions including 0 0 where nothing happens
fullGrid <- matrix(c(0,    0,1,     1,1,3),3,2,byrow=TRUE)
View(fullGrid)
View(fullGrid)
fullGrid
fullGrid <- matrix(c(1,    0,1,     1,1,3),3,2,byrow=TRUE)
fullGrid
unlist(1,2) <- magnitudeMI
?optim
extentRetract <- function(i){pSampleNegTag*exp(-i*parms[2])}
extentRetract(2)
pSampleNegTag <- .65 #no longer a probability but a proportion
magnitudeMI   <- 11 #starting "strength" of MI
#misinfo scores in E1
scores <- c(.39,4.48,1.83)
scores <- scores-scores[1] #form zero baseline
#get all conditions including 0 0 where nothing happens
fullGrid <- matrix(c(1,    0,1,     1,1,3),3,2,byrow=TRUE)
#nMI nR in that order in each row now
#convert parameter variables into single array for fminsearch
startparms <- c(pSampleNegTag,magnitudeMI)
doMIsampling(startparms)
source('~/Students and Reflets/UoB Project Students/UB Project students 2016-17/Hannah Bougdah -- MSc ind diffs in 3R v 1R/hannah bougdah inddiff study/Hannah modeling code/doMisampling.R')
source('~/Students and Reflets/UoB Project Students/UB Project students 2016-17/Hannah Bougdah -- MSc ind diffs in 3R v 1R/hannah bougdah inddiff study/Hannah modeling code/doMisampling.R')
source('~/Students and Reflets/UoB Project Students/UB Project students 2016-17/Hannah Bougdah -- MSc ind diffs in 3R v 1R/hannah bougdah inddiff study/Hannah modeling code/doMisampling.R')
source('~/Students and Reflets/UoB Project Students/UB Project students 2016-17/Hannah Bougdah -- MSc ind diffs in 3R v 1R/hannah bougdah inddiff study/Hannah modeling code/doMisampling.R')
doMIsampling(startparms)
doMISampling(startparms)
?numel
?length
length
?dim
source('~/Students and Reflets/UoB Project Students/UB Project students 2016-17/Hannah Bougdah -- MSc ind diffs in 3R v 1R/hannah bougdah inddiff study/Hannah modeling code/MIdiscrepancy.R')
#sampleMisinfo -- checking out Ulli's ideas for PB&R paper
nMI <- c(1) #number of misinfo tokens at input
nR <- c(0,1,3) #number of retractions
nSamples <- 4
nTokens <- 12
nRep <- 1000
ulli <- 0 #ulli's model = 1, SL model = 0
pSampleNegTag <- .65 #no longer a probability but a proportion
magnitudeMI   <- 11 #starting "strength" of MI
#misinfo scores in E1
scores <- c(.39,4.48,1.83)
scores <- scores-scores[1] #form zero baseline
#get all conditions including 0 0 where nothing happens
fullGrid <- matrix(c(1,    0,1,     1,1,3),3,2,byrow=TRUE)
#nMI nR in that order in each row now
#convert parameter variables into single array for fminsearch
startparms <- c(pSampleNegTag,magnitudeMI)
#call parameter estimation....
misInfo <- optim(startparms,
fn = MIdiscrepancy,
scores)
misInfo <- optim(startparms,
fn = MIdiscrepancy,
data = scores)
misInfo
?optim
doMISampling(c(1,1))
doMISampling(c(1,0))
doMISampling(c(.1,0))
# analyze replication market results
library(plyr)
library(dplyr)
setwd("C:/Users/Lewan/Documents/MATLAB/Modeling/Replication market")
rm <- read.table("resultsSimfake.dat")
names(rm) <- c('phack','gain','typeI','power','nTotExptsPrivRep','nPrivRealInterestEffs','nPrivRealInterestTrueEffs',
'nTotExptsPubRep','nPubRealInterestEffs','nPubRealInterestTrueEffs')
#first plot error rates in initial exploration (before replication)
#this shows effects of p-hacking
g5 <- filter(rm,gain==5) #identical for all levels of gain (no decision being made about replication)
x11()
plot(g5$phack,g5$typeI,ylim=c(0,.3),xlab="p-Hacking (batch size)", ylab="Type I/II error rate",las=1,type="l")
points(g5$phack,g5$typeI,pch=21,bg="red",cex=2)
lines(g5$phack,1-g5$power)
points(g5$phack,1-g5$power,pch=21,bg="black",cex=2)
abline(h=.05,lty="dashed")
legend (5,.25,c("Type I","Type II"),pch=21,pt.cex=2,pt.bg=c("red","black"),lty="solid")
for (g in c(0,1,10)) {
g5 <- filter(rm,gain==g)
x11()
ul <- max(g5$nTotExptsPrivRep+2)
plot(g5$phack,g5$nTotExptsPrivRep,ylim=c(95,ul),xlab="p-Hacking (batch size)", ylab="Number of experiments conducted",
las=1,type="l")
points(g5$phack,g5$nTotExptsPrivRep,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nTotExptsPubRep)
points(g5$phack,g5$nTotExptsPubRep,pch=21,bg="blue",cex=2)
abline(h=100,lty="dashed")
#text(5,ul-2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
legend(4,112,c("Private replication","Public replication"),pch=21,pt.bg=c("red","blue"),lty="solid",pt.cex=2)
x11()
ul2 <- max(10, max(g5$nPrivRealInterestEffs,g5$nPubRealInterestEffs))
plot(g5$phack,g5$nPrivRealInterestTrueEffs,ylim=c(0,ul2),xlab="p-Hacking (batch size)",
ylab="Number of interesting (true) effects revealed",
las=1,type="l")
points(g5$phack,g5$nPrivRealInterestTrueEffs,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nPubRealInterestTrueEffs)
points(g5$phack,g5$nPubRealInterestTrueEffs,pch=21,bg="blue",cex=2)
lines(g5$phack,g5$nPrivRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPrivRealInterestEffs,pch=22,bg="red",cex=1.5)
lines(g5$phack,g5$nPubRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPubRealInterestEffs,pch=22,bg="blue",cex=1.5)
#text(5,ul2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
abline(h=9,lty="dashed")
legend(3,7,c("True effects private replication","True effects public replication",
"Interesting effects private replication","Interesting effects public replication"),
pch=c(21,21,22,22),pt.bg=c("red","blue","red","blue"),lty=c("solid","solid","dashed","dashed"),pt.cex=2)
}
# analyze replication market results
library(plyr)
library(dplyr)
setwd("C:/Users/Lewan/Documents/MATLAB/Modeling/Replication market")
rm <- read.table("resultsSimfake.dat")
names(rm) <- c('phack','gain','typeI','power','nTotExptsPrivRep','nPrivRealInterestEffs','nPrivRealInterestTrueEffs',
'nTotExptsPubRep','nPubRealInterestEffs','nPubRealInterestTrueEffs')
#first plot error rates in initial exploration (before replication)
#this shows effects of p-hacking
g5 <- filter(rm,gain==5) #identical for all levels of gain (no decision being made about replication)
x11()
plot(g5$phack,g5$typeI,ylim=c(0,.3),xlab="p-Hacking (batch size)", ylab="Type I/II error rate",las=1,type="l")
points(g5$phack,g5$typeI,pch=21,bg="red",cex=2)
lines(g5$phack,1-g5$power)
points(g5$phack,1-g5$power,pch=21,bg="black",cex=2)
abline(h=.05,lty="dashed")
legend (5,.25,c("Type I","Type II"),pch=21,pt.cex=2,pt.bg=c("red","black"),lty="solid")
for (g in c(0,1,10)) {
g5 <- filter(rm,gain==g)
x11()
ul <- max(g5$nTotExptsPrivRep+2)
plot(g5$phack,g5$nTotExptsPrivRep,ylim=c(95,ul),xlab="p-Hacking (batch size)", ylab="Number of experiments conducted",
las=1,type="l")
points(g5$phack,g5$nTotExptsPrivRep,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nTotExptsPubRep)
points(g5$phack,g5$nTotExptsPubRep,pch=21,bg="blue",cex=2)
abline(h=100,lty="dashed")
#text(5,ul-2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
legend(4,112,c("Private replication","Public replication"),pch=21,pt.bg=c("red","blue"),lty="solid",pt.cex=2)
x11()
ul2 <- max(10, max(g5$nPrivRealInterestEffs,g5$nPubRealInterestEffs))
plot(g5$phack,g5$nPrivRealInterestTrueEffs,ylim=c(0,ul2),xlab="p-Hacking (batch size)",
ylab="Number of interesting (true) effects revealed",
las=1,type="l")
points(g5$phack,g5$nPrivRealInterestTrueEffs,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nPubRealInterestTrueEffs)
points(g5$phack,g5$nPubRealInterestTrueEffs,pch=21,bg="blue",cex=2)
lines(g5$phack,g5$nPrivRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPrivRealInterestEffs,pch=22,bg="red",cex=1.5)
lines(g5$phack,g5$nPubRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPubRealInterestEffs,pch=22,bg="blue",cex=1.5)
#text(5,ul2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
abline(h=9,lty="dashed")
legend(3,7,c("True effects private replication","True effects public replication",
"Interesting effects private replication","Interesting effects public replication"),
pch=c(21,21,22,22),pt.bg=c("red","blue","red","blue"),lty=c("solid","solid","dashed","dashed"),pt.cex=2)
}
graphics.off()
# analyze replication market results
library(plyr)
library(dplyr)
setwd("C:/Users/Lewan/Documents/MATLAB/Modeling/Replication market")
rm <- read.table("resultsSimfake.dat")
names(rm) <- c('phack','gain','typeI','power','nTotExptsPrivRep','nPrivRealInterestEffs','nPrivRealInterestTrueEffs',
'nTotExptsPubRep','nPubRealInterestEffs','nPubRealInterestTrueEffs')
#first plot error rates in initial exploration (before replication)
#this shows effects of p-hacking
g5 <- filter(rm,gain==5) #identical for all levels of gain (no decision being made about replication)
x11()
plot(g5$phack,g5$typeI,ylim=c(0,.3),xlab="p-Hacking (batch size)", ylab="Type I/II error rate",las=1,type="l")
points(g5$phack,g5$typeI,pch=21,bg="red",cex=2)
lines(g5$phack,1-g5$power)
points(g5$phack,1-g5$power,pch=21,bg="black",cex=2)
abline(h=.05,lty="dashed")
legend (5,.25,c("Type I","Type II"),pch=21,pt.cex=2,pt.bg=c("red","black"),lty="solid")
for (g in c(0,1,10)) {
g5 <- filter(rm,gain==g)
x11()
ul <- max(g5$nTotExptsPrivRep+2)
ll <- min(95, g5$nTotExptsPubRep-2)
plot(g5$phack,g5$nTotExptsPrivRep,ylim=c(ll,ul),xlab="p-Hacking (batch size)", ylab="Number of experiments conducted",
las=1,type="l")
points(g5$phack,g5$nTotExptsPrivRep,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nTotExptsPubRep)
points(g5$phack,g5$nTotExptsPubRep,pch=21,bg="blue",cex=2)
abline(h=100,lty="dashed")
#text(5,ul-2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
legend(4,112,c("Private replication","Public replication"),pch=21,pt.bg=c("red","blue"),lty="solid",pt.cex=2)
x11()
ul2 <- max(10, max(g5$nPrivRealInterestEffs,g5$nPubRealInterestEffs))
plot(g5$phack,g5$nPrivRealInterestTrueEffs,ylim=c(0,ul2),xlab="p-Hacking (batch size)",
ylab="Number of interesting (true) effects revealed",
las=1,type="l")
points(g5$phack,g5$nPrivRealInterestTrueEffs,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nPubRealInterestTrueEffs)
points(g5$phack,g5$nPubRealInterestTrueEffs,pch=21,bg="blue",cex=2)
lines(g5$phack,g5$nPrivRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPrivRealInterestEffs,pch=22,bg="red",cex=1.5)
lines(g5$phack,g5$nPubRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPubRealInterestEffs,pch=22,bg="blue",cex=1.5)
#text(5,ul2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
abline(h=9,lty="dashed")
legend(3,7,c("True effects private replication","True effects public replication",
"Interesting effects private replication","Interesting effects public replication"),
pch=c(21,21,22,22),pt.bg=c("red","blue","red","blue"),lty=c("solid","solid","dashed","dashed"),pt.cex=2)
}
graphics.off()
# analyze replication market results
library(plyr)
library(dplyr)
setwd("C:/Users/Lewan/Documents/MATLAB/Modeling/Replication market")
rm <- read.table("resultsSimfake.dat")
names(rm) <- c('phack','gain','typeI','power','nTotExptsPrivRep','nPrivRealInterestEffs','nPrivRealInterestTrueEffs',
'nTotExptsPubRep','nPubRealInterestEffs','nPubRealInterestTrueEffs')
#first plot error rates in initial exploration (before replication)
#this shows effects of p-hacking
g5 <- filter(rm,gain==5) #identical for all levels of gain (no decision being made about replication)
x11()
plot(g5$phack,g5$typeI,ylim=c(0,.3),xlab="p-Hacking (batch size)", ylab="Type I/II error rate",las=1,type="l")
points(g5$phack,g5$typeI,pch=21,bg="red",cex=2)
lines(g5$phack,1-g5$power)
points(g5$phack,1-g5$power,pch=21,bg="black",cex=2)
abline(h=.05,lty="dashed")
legend (5,.25,c("Type I","Type II"),pch=21,pt.cex=2,pt.bg=c("red","black"),lty="solid")
for (g in c(0,1,10)) {
g5 <- filter(rm,gain==g)
x11()
ul <- max(g5$nTotExptsPrivRep+2)
ll <- min(95, g5$nTotExptsPubRep-2)
plot(g5$phack,g5$nTotExptsPrivRep,ylim=c(ll,ul),xlab="p-Hacking (batch size)", ylab="Number of experiments conducted",
las=1,type="l")
points(g5$phack,g5$nTotExptsPrivRep,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nTotExptsPubRep)
points(g5$phack,g5$nTotExptsPubRep,pch=21,bg="blue",cex=2)
abline(h=100,lty="dashed")
#text(5,ul-2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
legend(4,ul-10,c("Private replication","Public replication"),pch=21,pt.bg=c("red","blue"),lty="solid",pt.cex=2)
x11()
ul2 <- max(10, max(g5$nPrivRealInterestEffs,g5$nPubRealInterestEffs))
plot(g5$phack,g5$nPrivRealInterestTrueEffs,ylim=c(0,ul2),xlab="p-Hacking (batch size)",
ylab="Number of interesting (true) effects revealed",
las=1,type="l")
points(g5$phack,g5$nPrivRealInterestTrueEffs,pch=21,bg="red",cex=2)
lines(g5$phack,g5$nPubRealInterestTrueEffs)
points(g5$phack,g5$nPubRealInterestTrueEffs,pch=21,bg="blue",cex=2)
lines(g5$phack,g5$nPrivRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPrivRealInterestEffs,pch=22,bg="red",cex=1.5)
lines(g5$phack,g5$nPubRealInterestEffs,lty="dashed")
points(g5$phack,g5$nPubRealInterestEffs,pch=22,bg="blue",cex=1.5)
#text(5,ul2,paste("g=",as.character(g),sep=""),cex=2)
title(main=paste("g=",as.character(g),sep=""),cex=2)
abline(h=9,lty="dashed")
legend(3,7,c("True effects private replication","True effects public replication",
"Interesting effects private replication","Interesting effects public replication"),
pch=c(21,21,22,22),pt.bg=c("red","blue","red","blue"),lty=c("solid","solid","dashed","dashed"),pt.cex=2)
}
graphics.off()
order(rand(10))
order(rnorm(10))
rnorm(10)[order,]
xx<-rnorm(10)
xx[order(xx)]
choose
choose(101,2)
101^2
#random walk model
nreps <- 10000
nsamples <- 2000
drift <- 0.03  # 0 = noninformative stimulus would; >0 = informative
sdrw <- 0.3
criterion <- 3
latencies <- rep(0,nreps)
responses <- rep(0,nreps)
evidence <- matrix(0, nreps, nsamples+1)
for (i in c(1:nreps)) {
evidence[i,] <- cumsum(c(0,rnorm(nsamples,drift,sdrw)))
p <-  which(abs(evidence[i,])>criterion)[1]
responses[i] <- sign(evidence[i,p])
latencies[i]  <- p
}
#plot up to 5 random walk paths
tbpn <- min(nreps,5)
plot(1:max(latencies[1:tbpn])+10,type="n",las=1,
ylim=c(-criterion-.5,criterion+.5),
ylab="Evidence",xlab="Decision time")
for (i in c(1:tbpn)) {
lines(evidence[i,1:(latencies[i]-1)])
}
abline(h=c(criterion,-criterion),lty="dashed")
#plot histograms of latencies
par(mfrow=c(2,1))
toprt <- latencies[responses>0]
topprop <- length(toprt)/nreps
hist(toprt,col="gray",
xlab="Decision time", xlim=c(0,max(latencies)),
main=paste("Top responses (",as.numeric(topprop),
") m=",as.character(signif(mean(toprt),4)),
sep=""),las=1)
botrt <- latencies[responses<0]
botprop <- length(botrt)/nreps
hist(botrt,col="gray",
xlab="Decision time",xlim=c(0,max(latencies)),
main=paste("Bottom responses (",as.numeric(botprop),
") m=",as.character(signif(mean(botrt),4)),
sep=""),las=1)
#random walk model with unequal latencies between responses classes
nreps <- 1000
nsamples <- 2000
drift <- 0.03  # 0 = noninformative stimulus; >0 = informative
sdrw <- 0.3
criterion <- 3
t2tsd  <- c(0.0,0.025)
latencies <- rep(0,nreps)
responses <- rep(0,nreps)
evidence <- matrix(0, nreps, nsamples+1)
for (i in c(1:nreps)) {
sp <- rnorm(1,0,t2tsd[1])
dr <- rnorm(1,drift,t2tsd[2])
evidence[i,] <- cumsum(c(sp,rnorm(nsamples,dr,sdrw)))
p <-  which(abs(evidence[i,])>criterion)[1]
responses[i] <- sign(evidence[i,p])
latencies[i]  <- p
}
#plot up to 5 random walk paths
tbpn <- min(nreps,5)
plot(1:max(latencies[1:tbpn])+10,type="n",las=1,
ylim=c(-criterion-.5,criterion+.5),
ylab="Evidence",xlab="Decision time")
for (i in c(1:tbpn)) {
lines(evidence[i,1:(latencies[i]-1)])
}
abline(h=c(criterion,-criterion),lty="dashed")
#plot histograms of latencies
par(mfrow=c(2,1))
toprt <- latencies[responses>0]
topprop <- length(toprt)/nreps
hist(toprt,col="gray",
xlab="Decision time", xlim=c(0,max(latencies)),
main=paste("Top responses (",as.numeric(topprop),
") m=",as.character(signif(mean(toprt),4)),
sep=""),las=1)
botrt <- latencies[responses<0]
botprop <- length(botrt)/nreps
hist(botrt,col="gray",
xlab="Decision time",xlim=c(0,max(latencies)),
main=paste("Bottom responses (",as.numeric(botprop),
") m=",as.character(signif(mean(botrt),4)),
sep=""),las=1)
rm(list=ls())
#discrepancy for power forgetting function
powdiscrep <- function (parms,rec,ri) {
if (any(parms<0)||any(parms>1)) return(1e6)
pow_pred <- parms["a"] *(parms["b"]*ri + 1)^(-parms["c"])
return(sqrt( sum((pow_pred-rec)^2)/length(ri) ))
}
#Carpenter et al. (2008) Experiment 1
rec <- c(.93,.88,.86,.66,.47,.34)
ri  <- c(.0035, 1, 2, 7, 14, 42)
#initialize starting values
sparms <-c(1,.05,.7)
names(sparms) <- c("a","b","c")
#obtain best-fitting estimates
pout <- optim(sparms,powdiscrep,rec=rec,ri=ri)
pow_pred <- pout$par["a"] *(pout$par["b"]*c(0:max(ri)) + 1)^(-pout$par["c"])
#plot data and best-fitting predictions
x11()
par(cex.axis=1.2,cex.lab=1.4)
par(mar=(c(5, 5, 3, 2) + 0.1),las=1)
plot(ri,rec,
xlab = "Retention Interval (Days)",
ylab = "Proportion Items Retained",
ylim=c(0.3,1),xlim=c(0,43),xaxt="n",type="n")
lines(c(0:max(ri)),pow_pred,lwd=2)
points(ri,rec,pch=21, bg="dark grey",cex=2)
dev <- pow_pred[ri+1]
for (x in c(1:length(ri))) {
lines(c(ri[x],ri[x]),c(dev[x],rec[x]),lwd=1)
}
axis(1,at=c(0:43))
#perform bootstrapping analysis
ns  <- 55
nbs <- 1000
bsparms <- matrix(NA,nbs,length(sparms))
bspow_pred <- pout$par["a"] *(pout$par["b"]*ri + 1)^(-pout$par["c"])
for (i in c(1:nbs)) {
recsynth     <- vapply(bspow_pred, FUN=function(x) mean(rbinom(ns,1,x)), numeric(1))
bsparms[i,]  <- unlist(optim(pout$par,powdiscrep,rec=recsynth,ri=ri)$par)
}
#function to plot a histogram
histoplot<-function(x,l4x) {
hist(x,xlab=l4x,main="",xlim=c(0,1),cex.lab=1.5,cex.axis=1.5)
lq <- quantile(x,0.025)
abline(v=lq,lty="dashed",lwd=2)
uq <- quantile(x,0.975)
abline(v=uq,lty="dashed",lwd=2)
return(c(lq,uq))
}
x11(5,2)
par(mfcol=c(1,3),las=1)
for (i in c(1:dim(bsparms)[2])) {
print(histoplot(bsparms[,i],names(sparms)[i]))
}
#plot data and current predictions
getregpred <- function(parms,data) {
getregpred <- parms["b0"] + parms["b1"]*data[ ,2]
#wait with drawing a graph until key is pressed
par(ask=TRUE)
plot   (data[ ,2], type="n", las=1, ylim=c(-2,2), xlim=c(-2,2), xlab="X", ylab="Y")
par(ask=FALSE)
points (data[ ,2], data[ ,1], pch=21, bg="gray")
lines  (data[ ,2], getregpred, lty="solid")
return(getregpred)
}
#obtain current predictions and compute discrepancy
rmsd <-function(parms, data1) {
preds<-getregpred(parms, data1)
rmsd<-sqrt(sum((preds-data1[ ,1])^2)/length(preds))
}
#define parameters to generate data
nDataPts  <- 20
rho       <- .8
intercept <- .0
#generate synthetic data
data<-matrix(0,nDataPts,2)
data[ ,2] <- rnorm(nDataPts)
data[ ,1] <- rnorm(nDataPts)*sqrt(1.0-rho^2) + data[ ,2]*rho + intercept
#do conventional regression analysis
lm(data[,1] ~ data[,2])
#assign starting values
startParms <- c(-1., .2)
names(startParms) <- c("b1", "b0")
#obtain parameter estimates
xout <- optim(startParms, rmsd, data1=data)
#perform SDT via ABC
#simulate sdt given parameters and number of trials
simsdt<- function(d,b,ntrials) {
old <- rnorm(ntrials/2,d)
hits <-sum(old>(d/2+b))/(ntrials/2)*100
new <- rnorm(ntrials/2,0)
fas <- sum(new>(d/2+b))/(ntrials/2)*100
return(X<-c(hits,fas))
}
y   <- c(60,11)  #define target data
dmu <- 1         #define hyperparameters
bmu <- 0
dsigma <- bsigma <- 1
ntrials <- 100
epsilon <- 1
posterior <- matrix(0,1000,2)
for (s in c(1:1000)) {  #commence ABC
while(TRUE) {
dprop <- rnorm(1,dmu,dsigma)
bprop <- rnorm(1,bmu,bsigma)
X<-simsdt(dprop,bprop,ntrials) #simulate proposal
if (sqrt(sum((y-X)^2)) <= epsilon) {break}
}
posterior[s,]<-c(dprop,bprop) #keep good simulation
print(s)                      #show sign of life
}
apply(posterior,2,mean)
apply(posterior,2,FUN=function(x) quantile(x,c(.025,.975)))
apply(posterior,2,hist)
print(c(s,sqrt(sum((y-X)^2)),X,posterior[s,]))
#perform MCMC
burnin<-200
chain <- rep(0,5000)
obs <- 144
propsd <- 2     #tuning parameter
chain[1] <- 150  #starting value
for (i in 2:length(chain)) {
current <- chain[i-1]
proposal <- current + rnorm(1,0,propsd)
if (dnorm(obs,proposal,15) > dnorm(obs,current,15)) {
chain[i] <- proposal  #accept proposal
} else {
chain[i] <- ifelse(runif(1) < dnorm(obs,proposal,15)/dnorm(obs,current,15),
proposal,
current)
}
}
hist(chain)
mean(chain)
plot(density(chain),las=1,xlab=bquote("Sampled values of "*mu),
yaxt="n",lwd=2,lty="dashed",
main="",xlim=c(100,200),ylab="",
ylim=c(0,max(max(density(chain)$y),
max(density(chain[-c(1:burnin)])$y),
max(dnorm(c(100:200),144,15)))*1.4))
lines(density(chain[-c(1:burnin)]),lwd=2,lty="solid")
lines(c(100:200),dnorm(c(100:200),144,15),col="red",lwd=2)
mtext("   Density",2,1)
legend("topright",inset=.02,c("Normal PDF","All MCMC","Excluding burnin"),
lty=c("solid","dashed","solid"),col=c("red","black","black"),lwd=2)
plot(chain,type="l",las=1,xlab="Iteration",ylab="Value of accepted sample")
lines(1:burnin,chain[1:burnin],col="red")
